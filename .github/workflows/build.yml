# For more information see: https://help.github.com/actions/language-and-framework-guides/using-nodejs-with-github-actions

name: Patient file CI # https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#name

on:
  push:
    branches: [master]
  pull_request:
    branches: [master]

jobs:
  webclient-app: # This is the first job https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobs
    runs-on: ubuntu-18.04 # For the list of github hosted runners see https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idruns-on
    steps:
      # ifconfig # Commented this since local runner act does not have ifconfig in ubuntu full
      - name: Goal 1 -> Get env info
        run: |
          whoami    
          ls
          pwd
          docker-compose -v  
          docker -v

      - name: Goal 2 -> Check out repository code
        uses: actions/checkout@v2 # This is bringing source code to ubuntu server defined in line 13 Location of checkout is /home/runner/work/emr/emr

      - name: Goal 3 -> Move code to expected folder
        run: |
          ls
          sudo mkdir -p /gt/sc-prog-repos/emr              
          sudo mv servers /gt/sc-prog-repos/emr/servers     # In source part of move not giving complete path so it runs on act and github
          sudo mv webclient /gt/sc-prog-repos/emr/webclient
          sudo mv puppet-for-testing /gt/sc-prog-repos/emr/puppet-for-testing
          sudo mv utils /gt/sc-prog-repos/emr/utils
          sudo mv .github /gt/sc-prog-repos/emr/.github
          sudo mkdir -p /tmp/logs # in this folder all logs are stored and then uploaded as a artifact. Not using /dev/shm since not available on mac
          sudo chmod -R 777 /tmp/logs
          sudo chmod -R 777 /gt/sc-prog-repos/emr/
          cd /gt/sc-prog-repos/emr/servers
          sudo rm -rf package-lock.json # remove old package-lock.json file from servers
          cd /gt/sc-prog-repos/emr/webclient
          sudo rm -rf package-lock.json # remove old package-lock.json file from webclient

      - name: Goal 4 -> Make sure /gt/sc-prog-repos has the code
        run: |
          ls -a /gt/sc-prog-repos/emr

      - name: Goal 5 -> Start docker containers, servers webclient and mariadb
        run: |
          cd /gt/sc-prog-repos/emr/.github/docker-used-by-workflow
          docker-compose up -d
          sleep 120

      - name: Goal 6 -> Make sure docker containers can ping each other. They have to be on the same network
        run: |
          docker ps -a
          docker network ls
          docker network inspect docker-used-by-workflow_default

      # For some time without password works and later it works with password.
      # Reason: MariaDB first creates a temp DB and then shuts down and creates the proper DB
      # Need to wait for this command to succed before going further. The time needed to wait changes at every run
      # blank root password is set in docker-compose-test.yml file
      - name: Goal 7 -> A. Get confitmation that mariaDB is responding to queries
        run: |
          docker exec -i mariadb mysql -u root -e "show databases"

      - name: Goal 8 -> A. init mariadb with 1. Database 2. Tables and 3. Mock data
        run: |
          docker exec -i mariadb /gt/sc-prog-repos/emr/utils/db/create-db-tables-mock-data-in-db.sh 
          # Ref: https://stackoverflow.com/questions/31578446/running-a-script-inside-a-docker-container-using-shell-script

      - name: Goal 9 -> Get confitmation that mariaDB has the databases/tables/mock data
        run: |
          docker exec -i mariadb mysql -u root -e "show databases"

      # wget run-on-docker_servers_1:8000/ will not work as
      # hostname run-on-docker_servers_1 is not known to host.
      # This hostname is only known inside docker network
      - name: Goal 10 -> Get confitmation that servers is running. Wget default is retry 20 times.
        run: |
          wget localhost:8000/public/api/reminders/v20/abcd

      - name: Goal 11 -> Make sure that servers is returning right results
        run: |
          cat abcd

      - name: Goal 12 -> Get confirmation that webclient is running. Wget default is retry 20 times.
        run: |
          wget localhost/

      - name: Goal 13 -> Make sure that webclient is returning right results
        run: |
          cat index.html

      - name: Goal 14 -> Make sure that a patient file opens
        run: |
          wget localhost/pf/abcd

      - name: Goal 15 -> Make sure that patient file gave correct results
        run: |
          cat abcd

      # this used a public docker that by default logs into userid 1000
      - name: Goal 16 -> get the logged in user in puppet-for-testing
        run: |
          docker exec -i puppet-for-testing whoami

      # In servers and webclient supervisor runs npm install.
      # Why puppeteer is installed from dockerfile and not installed from npm install inside supervisor or build.yml?
      # If run from supervisor -> npm install is taking long time and node simple-puppet-test-run.js was starting before npm install finished
      # Also the packages will not change often. So better to install the puppeteer packages inside Dockerfile. This makes each CI/CD run faster.

      # The env must have the display variable set.
      - name: Goal 17 -> Checking env for virtual display for puppeteer Ref https://stackoverflow.com/a/56202410
        run: |
          docker exec -i puppet-for-testing env

      - name: Goal 18 -> Running a very simple puppeteer program
        run: |
          docker exec -i puppet-for-testing Xvfb :10 -ac &  
          docker exec -i puppet-for-testing node simple-puppet-test-run.js

      # This cannot be run from supervisor since then the pipleline will finish. Hence tests need to be run in the pipeline.
      # Programs run inside docker with supervisor are not in the pipeline. Even if program started from supervisor keeps running it will not stop the pipeline
      - name: Goal 19 -> run-tests
        run: |
          cd /gt/sc-prog-repos/emr/puppet-for-testing
          rm -rf rem # due to rem test in progress
          docker exec -i puppet-for-testing npm run start-test-on-git # check title of the page

      # in this folder all logs are stored and then uploaded as a artifact. Not using /dev/shm since not available on mac
      # actions that use a Dockerfile those files are probably created as the root user inside the container.  Because the upload-artifact action runs
      # as the runner user you will need to sudo chmod the permissions on those files so the runner user can read them.
      - name: Goal 20 -> Giving permission to logs folder
        if: always()
        run: |
          sudo chmod -R 777 /tmp/logs

      - name: Goal 21 -> Stopping all docker containers, So that logs get cleanly written
        if: always()
        run: |
          cd /gt/sc-prog-repos/emr/.github/docker-used-by-workflow
          # Not doing this since devs want the dockers running so they can debug
          # docker-compose down
          sleep 10

      - name: Goal 22 -> Upload result of tests
        # https://stackoverflow.com/questions/58858429/how-to-run-a-github-actions-step-even-if-the-previous-step-fails-while-still-f
        if: always()
        uses: actions/upload-artifact@v2
        with:
          name: logs
          path: /tmp/logs/
#
#
#
#
# Q1) What is the tree structure?
# The tree strcuture is
#  -- Workflow (Made up of 1 or more jobs)
#    -- Jobs (Jobs run in parallel by default. Each job runs in a fresh version of the virtual environment)
#       -- Services
#       -- Steps # Job contains a sequence of tasks called steps https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idsteps
#          -- name
#          -- uses
#          -- run
#
#
#
#
# Q2) Why have 3 services and not 3 jobs?
# The 3 docker containers are not run as 3 different jobs.
# A. Since ptserver job needs mysql server job to stay on. But mysql-server is not waiting for ptserver
# Future RnD:
# https://github.community/t/keep-jobs-services-alive/118912
# https://github.community/t/mariadb-mysql-service-is-unealthy/17390
# B. When run as 3 services each can ping the other with the hostname of the service given by docker.
#
#
#
#
# Q3) How to get source code inside ptserver and webclient images?
# Option1: On github I can create a custom docker image at each commit and then inside build.yml I can say:
# ptserver:
#  image: ptserver-node:14 Ref: https://www.learncloudnative.com/blog/2020-02-20-github-action-build-push-docker-images/
#
# Option 2:
# volume mount for e.g at:
# https://github.community/t/keep-jobs-services-alive/118912
# https://github.community/t/custom-docker-action-mounted-volumes/17013
#
# Preferred: Option 2
#
# Q4) How to see dockler logs
# Comment this when running tests. Since docker logs command does not exit.
# - name: See docker logs
#  run: |
#    cd /gt/sc-prog-repos/emr/utils/run-on-docker
#    docker logs --follow run-on-docker_ptserver_1
# https://stackoverflow.com/questions/61078178/github-action-how-to-ensure-that-server-is-running-properly
# in docker-compose webclient listens on port 80 Ref: https://unix.stackexchange.com/questions/5277/how-do-i-tell-a-script-to-wait-for-a-process-to-start-accepting-requests-on-a-po
# https://docs.github.com/en/actions/configuring-and-managing-workflows/persisting-workflow-data-using-artifacts
